{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_classification_demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YaxuanWei/resume-job-matcher/blob/master/keras_classification_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-rqNElZ-UtHj",
        "colab_type": "code",
        "colab": {},
        "outputId": "523d3b1a-92fc-40e6-87b2-1d6d6720f413"
      },
      "cell_type": "code",
      "source": [
        "# Code adpated from http://hunterheidenreich.com/blog/keras-text-classification-part-1/\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print('# of Training Samples: {}'.format(len(x_train)))\n",
        "print('# of Test Samples: {}'.format(len(x_test)))\n",
        "print('change something through colab.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of Training Samples: 8982\n",
            "# of Test Samples: 2246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hcGswR9VUtHp",
        "colab_type": "code",
        "colab": {},
        "outputId": "e10f70de-a499-4424-e912-be052b6697cd"
      },
      "cell_type": "code",
      "source": [
        "num_classes = max(y_train) + 1\n",
        "print('# of Classes: {}'.format(num_classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of Classes: 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D4c1l_lDUtHt",
        "colab_type": "code",
        "colab": {},
        "outputId": "7c34a242-be57-44c0-8ce5-c7260dc93995"
      },
      "cell_type": "code",
      "source": [
        "index_to_word = {}\n",
        "for key, value in word_index.items():\n",
        "    index_to_word[value] = key\n",
        "print(' '.join([index_to_word[x] for x in x_train[0]]))\n",
        "print(y_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the wattie nondiscriminatory mln loss for plc said at only ended said commonwealth could 1 traders now april 0 a after said from 1985 and from foreign 000 april 0 prices its account year a but in this mln home an states earlier and rise and revs vs 000 its 16 vs 000 a but 3 psbr oils several and shareholders and dividend vs 000 its all 4 vs 000 1 mln agreed largely april 0 are 2 states will billion total and against 000 pct dlrs\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eq1w0LbeUtHw",
        "colab_type": "code",
        "colab": {},
        "outputId": "c733e6ec-c1ef-4c68-e480-183414991a34"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_words = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
        "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(x_train[0])\n",
        "print(len(x_train[0]))\n",
        "\n",
        "print(y_train[0])\n",
        "print(len(y_train[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. ... 0. 0. 0.]\n",
            "10000\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D6zy1rZ-UtHz",
        "colab_type": "code",
        "colab": {},
        "outputId": "a0d9d4c3-36b2-4164-d996-67de89180ace"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.metrics_names)\n",
        "['loss', 'acc']\n",
        "batch_size = 32\n",
        "# TODO: replace 3 when real training.\n",
        "epochs = 3\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)\n",
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/hayden/Envs/jupyter/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /Users/hayden/Envs/jupyter/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "['loss', 'acc']\n",
            "Train on 8083 samples, validate on 899 samples\n",
            "WARNING:tensorflow:From /Users/hayden/Envs/jupyter/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/3\n",
            "8083/8083 [==============================] - 10s 1ms/sample - loss: 1.2722 - acc: 0.7234 - val_loss: 0.9475 - val_acc: 0.7998\n",
            "Epoch 2/3\n",
            "8083/8083 [==============================] - 10s 1ms/sample - loss: 0.4908 - acc: 0.8898 - val_loss: 0.8562 - val_acc: 0.8165\n",
            "Epoch 3/3\n",
            "8083/8083 [==============================] - 10s 1ms/sample - loss: 0.2885 - acc: 0.9354 - val_loss: 0.9072 - val_acc: 0.8131\n",
            "2246/2246 [==============================] - 0s 193us/sample - loss: 0.8795 - acc: 0.8090\n",
            "Test loss: 0.8795146086549291\n",
            "Test accuracy: 0.80899376\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}